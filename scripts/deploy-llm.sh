#!/bin/bash

# Deploy LLM-powered Voice Assistant with AWS Bedrock Claude Haiku
# Most cost-effective LLM solution: ~90% cheaper than OpenAI

echo "ðŸ§  Deploying LLM-powered Voice Assistant with AWS Bedrock Claude Haiku"
echo "ðŸ’° Cost: ~$0.00025 per 1K input tokens, ~$0.00125 per 1K output tokens"

# Set variables
REGION="us-east-1"
PROJECT_NAME="voice-assistant-ai"

# Check if AWS CLI is configured
if ! aws sts get-caller-identity > /dev/null 2>&1; then
    echo "âŒ AWS CLI not configured. Please run 'aws configure' first."
    exit 1
fi

echo "âœ… AWS CLI configured"

# Check if Bedrock Claude Haiku is available in region
echo "ðŸ” Checking Bedrock model availability..."
if aws bedrock list-foundation-models --region $REGION --query 'modelSummaries[?modelId==`anthropic.claude-3-haiku-20240307-v1:0`]' --output text | grep -q "anthropic.claude-3-haiku"; then
    echo "âœ… Claude Haiku model available in $REGION"
else
    echo "âŒ Claude Haiku model not available in $REGION. Please check Bedrock console."
    exit 1
fi

# Navigate to terraform directory
cd "$(dirname "$0")/../infra/terraform" || exit 1

# Initialize Terraform
echo "ðŸ—ï¸ Initializing Terraform..."
terraform init

# Plan deployment
echo "ðŸ“‹ Planning LLM infrastructure deployment..."
terraform plan -var="aws_region=$REGION"

# Ask for confirmation
read -p "ðŸš€ Deploy LLM infrastructure? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "âŒ Deployment cancelled"
    exit 1
fi

# Apply Terraform
echo "ðŸš€ Deploying LLM infrastructure..."
terraform apply -auto-approve -var="aws_region=$REGION"

# Get outputs
API_URL=$(terraform output -raw llm_api_gateway_url 2>/dev/null || echo "Not available")
CONVERSATION_TABLE=$(terraform output -raw conversation_table_name 2>/dev/null || echo "Not available")

echo ""
echo "ðŸŽ‰ LLM Voice Assistant Deployed Successfully!"
echo ""
echo "ðŸ“Š Infrastructure Details:"
echo "  â€¢ Model: Claude Haiku (most cost-effective)"
echo "  â€¢ API Gateway: $API_URL"
echo "  â€¢ Conversation Table: $CONVERSATION_TABLE"
echo "  â€¢ Region: $REGION"
echo ""
echo "ðŸ’° Cost Optimization Features:"
echo "  â€¢ Claude Haiku: ~90% cheaper than GPT-4"
echo "  â€¢ Conversation history limited to 8 exchanges"
echo "  â€¢ Max tokens: 300 (optimized for cost)"
echo "  â€¢ DynamoDB Pay-per-request billing"
echo ""
echo "ðŸŽ¯ Expected Monthly Costs (light usage):"
echo "  â€¢ Bedrock Claude Haiku: $0.50-2.00"
echo "  â€¢ Lambda: $0.20-1.00"
echo "  â€¢ DynamoDB: $0.25-1.00"
echo "  â€¢ API Gateway: $0.10-0.50"
echo "  â€¢ Total: ~$1-5/month"
echo ""
echo "ðŸ”— Next Steps:"
echo "  1. Update frontend to use new API endpoint"
echo "  2. Test LLM conversations"
echo "  3. Monitor costs in AWS Cost Explorer"
echo ""
echo "âœ… LLM deployment complete!"
